---
title: "MLE_Ridge_Forest"
author: "Group 3"
date: "2025-12-07"
output: html_document
---

\colorlet{shadecolor}{gray!10}
```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(MASS)
library(GGally)
library(tidymodels)
library(glmnet)
library(pROC)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, tidy = FALSE)
```
\newcommand{\hstart}{ \colorlet{shadecolor}{green!20}
\begin{shaded} }
\newcommand{\hstop}{  \end{shaded} \colorlet{shadecolor}{gray!10}}

\hstart

# MLE vs. Ridge Regression vs. Random Forest

We compare the three modeling approaches under the same Monte Carlo simulation design used earlier.

\hstop

```{r}
# loading Monte Carlo results datasets

mle_df <- read.csv("MLE_Simulation.csv")
ridge_df <- read.csv("results_files/ridge_mc_testing_results.csv")
rf_df <- read.csv("RandomForest_Simulation.csv")

```

```{r}
# creating a master table
all_results <- bind_rows(mle_df, rf_df)
head(all_results)

```

\hstart

### Boxplots
AUC boxplot distribution

\hstop

```{r}
# AUC
ggplot(all_results, aes(x = model, y = AUC, fill = model)) +
  geom_boxplot(alpha = 0.7, outlier.alpha = 0.3) +
  facet_grid(EPV ~ P) +
  labs(title = "AUC Distribution Across Methods",
       x = "Model", 
       y = "AUC")

```

```{r}
# Briar
ggplot(all_results, aes(x = model, y = Brier, fill = model)) +
  geom_boxplot(alpha = 0.7, outlier.alpha = 0.3) +
  facet_grid(EPV ~ P) +
  labs(title = "Brier Score Distribution Across Methods", 
       x = "Model", 
       y = "Brier Score")

```

```{r}
# compute means for heatmap
# method * EPV * P

mean_results <- all_results |>
  group_by(model, EPV, P) |>
  summarise(mean_AUC = mean(AUC), mean_Brier = mean(Brier), .groups = "drop")

mean_results

 
```

```{r}
# heatmap for mean AUC

ggplot(mean_results, aes(x = factor(P), y = factor(EPV), fill = mean_AUC)) +
  geom_tile() +
  facet_wrap(~ model) + 
  scale_fill_viridis_c(option = "plasma") +
  labs(title = "Heatmap of Mean AUC",
    x = "Number of Predictors (P)",
    y = "EPV",
    fill = "Mean AUC"
  )

```

```{r}
ggplot(mean_results, aes(x = factor(P), y = factor(EPV), fill = mean_Brier)) +
  geom_tile() +
  facet_wrap(~ model) + 
  scale_fill_viridis_c(option = "magma") +
  labs(title = "Heatmap of Mean Brier Score",
    x = "Number of Predictors (P)",
    y = "EPV",
    fill = "Mean Brier"
  )

```

# read in resimulated data
```{r}
ridge_extra <- read.csv("simulations_rmse_mae/ridge_simulation_extra_values.csv")
mle_extra <- read.csv("simulations_rmse_mae/mle_simulation_extra_values.csv")
rf_extra <- read.csv("simulations_rmse_mae/random_forest_simulation_extra_values.csv")
rf_extra$model <- "Random Forest"
mle_extra$model <- "ML"

combined_metrics <- rbind(ridge_extra, mle_extra)
combined_metrics <- rbind(combined_metrics, rf_extra)
```

```{r}
fig2 <- combined_metrics |> pivot_longer(cols = c(rMPSE, MAPE, Brier), 
                                         names_to = "measure",
                                         values_to = "value") |>
  mutate(measure = factor(measure, level = c("rMPSE", "MAPE", "Brier")),
         model = factor(model, level = c("Ridge", "ML", "Random Forest")))

<<<<<<< HEAD

ggplot(combined_long) + 
=======
ggplot(fig3) + 
>>>>>>> refs/remotes/origin/main
  geom_boxplot(aes(x = model, y = value)) + 
  facet_wrap(measure ~ EPV) 

ggplot(combined_long) + 
  geom_tile(aes(x = P, y = model, fill = value))+ 
  facet_wrap(. ~ measure)
```

```{r}
fig3 <- fig2 |>
  mutate(P = factor(P),
        beta_pattern = factor(beta_pattern),
        rho = factor(rho))|> 
  pivot_longer(cols = c(P, beta_pattern, rho), 
                             names_to = "parameter",
                            values_to = "stage") 
ggplot(fig3) + 
  geom_tile(aes(x = stage, y = model, fill = value))+ 
  scale_fill_viridis_c(option = "rocket") +
  facet_wrap(measure ~ parameter, scales = "free") 
```

