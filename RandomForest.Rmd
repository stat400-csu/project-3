---
title: "RandomForest"
output: html_document
---
# load libraries
```{r}
packages <- c("tidyverse", "tidymodels", "rpart.plot", "vip", "Metrics", "randomForest", 
              "MASS", "pROC", "ggplot2", "tibble")

for (pkg in packages) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}
remove(packages, pkg)
```

# simulate train and test data
```{r}
simulate_logit <- function(N, P, rho, beta_pattern) {
  Sigma <- matrix(rho, P, P)
  diag(Sigma) <- 1
  
  X <- mvrnorm(n = N, mu = rep(0, P), Sigma = Sigma)
  
  if (beta_pattern == "equal") {
    beta <- rep(0.5, P)
  } else if (beta_pattern == "strong") {
    beta <- c(1.0, rep(0.2, P-1))
  } else if (beta_pattern == "noise") {
    beta <- c(0, rep(0.3, P-1))
  } else if (beta_pattern == "halfnoise") {
    beta <- c(rep(0, P/2), rep(0.3, P/2))
  } else {
    stop("Unknown beta pattern")
  }
  
  eta <- X %*% beta
  pi  <- 1/(1 + exp(-eta))
  y <- as.factor(rbinom(N, 1, pi))
  
  data.frame(y = y, X)
}
```

# fit model on train data
```{r}
fit_rf <- function(dat) {
  rf_spec <- rand_forest(mtry = sqrt(.cols())) |>
  set_engine("randomForest", importance = TRUE) |>
  set_mode("classification")

  rf_fit <- rf_spec |>
  fit(y ~ ., data = dat)
}
```


# evaluate model on test data
- average loss of area under ROC curve: average difference between AUC of generated data and AUC of model (defined by distribution of predictor variables); higher values closer to zero indicate better discriminative performance
- median calibration slope (CS): closer to 1 = better performance, cs < 1 = overfitting, cs > 1 = underfitting
- average calibration in the large (CIL): difference between generated evens fraction and average estimated probabilities $\frac{\sum_{i} y_i}{N} - \frac{\sum_i \hat{\pi}_i}{N}$; closer to 0 = better performance, CIL > 0 = systematic overestimation of estimated probabilities, CIL < 0 = underestimation
- average Brier score
- square root of mean squared prediction error
- mean absolute prediction error

```{r}
evaluate_mle_model <- function(fit, dat) {
  probs <- augment(rf, new_data = dat) %>% pull(.pred_class)
  rmse(as.numeric(dat$y), as.numeric(probs))
  
  auc_val <- auc(as.numeric(dat$y), as.numeric(probs))
  brier <- mean((as.numeric(dat$y) - as.numeric(probs))^2)
  
  tibble(AUC = as.numeric(auc_val), Brier = brier, lambda = NA)
}
```

# try on one first
```{r}
  # generate data 
  EPV <- 50
  event_frac <- 0.5
  P <- 12
  rho <- 0.5
  bp <- "equal"
  
  # time model fit
  start <-Sys.time()
  
  # Determine total sample size
  N <- ceiling((EPV * P) / event_frac)
  N_star <- ceiling(5000/event_frac)
  
  # Simulate dataset
  df_train <- simulate_logit(N, P, rho, bp)
  df_test <- simulate_logit(N_star, P, rho, bp)
  
  # fit model
  rf <- fit_rf(df_train)
  
  # evaluate model
  results <- evaluate_mle_model(rf, df_test)
  
  end <-  Sys.time()
  end - start
  # about 2 seconds per model * 10 simulations * 72 models = 1,4000 seconds or 24 minutes
```


# run for all datasets
```{r}
set.seed(400)

EPV_vals <- c(5, 10, 50)
event_frac <- 0.5

P_vals <- c(4, 8, 12)
rho_vals <- c(0, 0.5)
beta_patterns <- c("equal", "strong", "noise", "halfnoise")

B <- 10  # number of Monte Carlo repetitions

all_results <- list()
iter <- 1

for (EPV in EPV_vals) {
  for (P in P_vals) {
    for (rho in rho_vals) {
      for (bp in beta_patterns) {
        for (b in 1:B) {
          
          # Determine total sample size
          N <- ceiling((EPV * P) / event_frac)
          N_star <- ceiling(5000/event_frac)
          
          # Simulate dataset
          df_train <- simulate_logit(N, P, rho, bp)
          df_test <- simulate_logit(N_star, P, rho, bp)
          
          # fit random forest
          fit_rf <- fit_logistic_mle(df_train)
          
          # evaluate random forest
          eval_rf <- evaluate_rf_model(fit_rf, df_test)
          eval_rf$model <- "Random Forest"
          
          ### Store combined ###
          combined <- eval_rf %>%
            mutate(
              EPV = EPV,
              P = P,
              rho = rho,
              beta_pattern = bp,
              sim = b
            )
          
          all_results[[iter]] <- combined
          iter <- iter + 1
        }
      }
    }
  }
}
```

