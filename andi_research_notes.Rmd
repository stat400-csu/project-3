---
title: "Research Notes"
author: "Andi"
date: "2025-12-07"
output: html_document
---

\colorlet{shadecolor}{gray!10}
```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(MASS)
library(GGally)
library(tidymodels)
library(glmnet)
library(pROC)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, tidy = FALSE)
```
\newcommand{\hstart}{ \colorlet{shadecolor}{green!20}
\begin{shaded} }
\newcommand{\hstop}{  \end{shaded} \colorlet{shadecolor}{gray!10}}

\hstart

### Sample size for binary logistic prediction models: Beyond events per variable criteria

\hstop

\hstart

### Citation APA:

van Smeden, M., Moons, K. G. M., de Groot, J. A. H., Collins, G. S., Altman, D. G., Eijkemans, M. J. C., & Reitsma, J. B. (2019). Sample size for binary logistic prediction models: Beyond events per variable criteria. Statistical Methods in Medical Research, 28(8), 2455–2474. https://doi.org/10.1177/0962280218784726

\hstop

\hstart

#### Abstract and Introduction:

Logistic regression is often used in clinical settings with a long-held standard is to use EPV (events per variable) ≥ 10 in order to decide on the minimal sample size and the maximum number of predictors to make the study stable. Events per variable is a ratio of the number of events / number of predictors. Having too small of a sample size or too large of a number of predictors the study can become unreliable.

A simulation study is presented that studies the influence of EPV, the events fraction, and the number of possible predictors. The predictive performance of correlations, distributions of possible predictor variables, and predictor effects on new simulated sample data are compared using methods such as rMSPE, calibration slope, and AUC.

The studies results indicate that EPV does not have a strong relation with the metrics of predictive performance. They suggest that predictive performance can be better approximated by considering 3 factors instead: the number of predictors, total sample size, and the events fraction (a ratio of positive outcomes over the total outcomes).

Arguments are that EPV = 10 is either too lenient or too strict with shrinkage models such as ridge and lasso, and that EPV doesn't reliably predict how well a model performs on new data. There is a gap in alternatives.

Goals of the research are to investigate what characteristics of a dataset actually do affect the testing sample data predictive performance in logistic regression.

Simulation Study:
Use a large Monte Carlo simulation and vary:
- EPV
- event fraction
- number of predictors
- predictor distributions
- effect sizes
- true model AUC

Models:
- Maximum Likelihood
- Backward selection
- Firth penalized likelihood
- Heuristic shrinkage
- Ridge regression
- LASSO regression

Variations:
- EPV
- events fraction
- number of candidate predictors
- type of predictor variable effects

\hstop

\hstart

#### 2. Developing a prediction model using logistic regression

#### a. Logistic Regression simulation

Synthetic datasets of known truth:
- Logistic regression model generates the probabilities
- Bernoulli generates the binary outcomes

#### b. Ridge Logistic Regression

- adds a penalty L2 to the loss function which shrinks the coefficients towards zero so they are less extreme
- purpose: stabilizes the model when predictors are correlated or when the dataset is small relative to the number of predictors
- reduces variance without adding too much bias -> keeps the variance/bias ratio in check

Predictive Performance 

- ridge is trained on synthetic data A
- ridge is tested on synthetic data B
- repeat

\hstop

\hstart

#### 3. Methods

\hstop

\hstart

#### 4. Results

\hstop

\hstart

#### 5. Discussion

\hstop

\hstart

#### Conclusions:

- suggest a new way for determining sample size based on actual predictive error instead of EPV cutoffs

\hstop

\hstart

#### Other Considerations:

Methods that are newer such as bootstrap validation offer sample size calculators to predict error, not just EPV.

\hstop
