---
title: "RandomForest"
output: html_document
---
# load libraries
```{r}
packages <- c("tidyverse", "tidymodels", "rpart.plot", "vip", "Metrics", "randomForest", 
              "MASS", "pROC", "ggplot2", "tibble", "GGally")

for (pkg in packages) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}
remove(packages, pkg)
```

# simulate train and test data
```{r}
simulate_logit <- function(N, P, rho, beta_pattern) {
  Sigma <- matrix(rho, P, P)
  diag(Sigma) <- 1
  
  X <- mvrnorm(n = N, mu = rep(0, P), Sigma = Sigma)
  
  if (beta_pattern == "equal") {
    beta <- rep(0.5, P)
  } else if (beta_pattern == "strong") {
    beta <- c(1.0, rep(0.2, P-1))
  } else if (beta_pattern == "noise") {
    beta <- c(0, rep(0.3, P-1))
  } else if (beta_pattern == "halfnoise") {
    beta <- c(rep(0, P/2), rep(0.3, P/2))
  } else {
    stop("Unknown beta pattern")
  }
  
  eta <- X %*% beta
  pi  <- 1/(1 + exp(-eta))
  y <- rbinom(N, 1, pi)
  
  data.frame(y = y, pi = pi, X)
}
```

# fit model on train data
```{r}

fit_rf_model <- function(dat) {
  # remove pi
  train_set <- dat |> subset(select = -pi) |> 
    mutate(y = as.factor(y))
  rf_spec <- rand_forest(mtry = sqrt(.cols())) |>
  set_engine("randomForest", importance = TRUE) |>
  set_mode("classification")

  rf_fit <- rf_spec |> fit(y ~ ., data = train_set)
  rf_fit
}

# ridge logistic regression function

fit_logistic_ridge <- function(dat) {
  # dat: data.frame with first column y and the rest predictors
  
  X <- as.matrix(dat |> subset(select = -c(y, pi)))  # all columns except y and pi
  y <- dat$y                  # first column is y
  
  # alpha = 0 -> ridge penalty
  cvfit <- cv.glmnet(
    x = X,
    y = y,
    alpha = 0, 
    family = "binomial"
  )
  
  cvfit
}

fit_logistic_mle <- function(dat) {
  glm(y ~ ., data = dat |> subset(select = -pi), family = binomial)
}
```


# evaluate model on test data
- average loss of area under ROC curve: average difference between AUC of generated data and AUC of model (defined by distribution of predictor variables); higher values closer to zero indicate better discriminative performance
- median calibration slope (CS): closer to 1 = better performance, cs < 1 = overfitting, cs > 1 = underfitting
- average calibration in the large (CIL): difference between generated evens fraction and average estimated probabilities $\frac{\sum_{i} y_i}{N} - \frac{\sum_i \hat{\pi}_i}{N}$; closer to 0 = better performance, CIL > 0 = systematic overestimation of estimated probabilities, CIL < 0 = underestimation
- average Brier score
- square root of mean squared prediction error
- mean absolute prediction error

```{r}
evaluate_rf_model <- function(fit, dat) {
  probs <- fit |> augment(new_data = dat) |> pull(.pred_1)
  
  # rmse for prediction
  rMPSE <- rmse(dat$pi, probs)
  # mae for prediction
  MAPE <- mae(dat$pi, probs)
  # brier
  brier <- mean((dat$y - probs)^2)
  
  tibble(
    rMPSE = rMPSE,
    MAPE = MAPE,
    Brier = brier # brier: measure of the accuracy of probabilistic predictions
  )
}

evaluate_ridge_model <- function(cvfit, dat) {
  X <- as.matrix(dat |> subset(select = -c(y, pi)))
  y <- dat$y
  
  # lambda.min from CV (the value that minimizes the error)
  probs <- predict(cvfit, newx = X, type = "response", s = "lambda.min")
  
  # rmse for prediction
  rMPSE <- rmse(dat$pi, probs)
  # mae for prediction
  MAPE <- mae(dat$pi, probs)
  # brier
  brier <- mean((y - probs)^2)
  
  tibble(
    rMPSE = rMPSE,
    MAPE = MAPE,
    Brier = brier # brier: measure of the accuracy of probabilistic predictions
  )
}

evaluate_mle_model <- function(fit, dat) {
  probs <- fit |> predict(newdata = dat, type = "response")
  
  # rmse for prediction
  rMPSE <- rmse(dat$pi, probs)
  # mae for prediction
  MAPE <- mae(dat$pi, probs)
  # brier
  brier <- mean((dat$y - probs)^2)
  
  tibble(
    rMPSE = rMPSE,
    MAPE = MAPE,
    Brier = brier # brier: measure of the accuracy of probabilistic predictions
  )
}
```

# try on one first
```{r}
  # generate data 
  EPV <- 5
  event_frac <- 0.5
  P <- 4
  rho <- 0
  bp <- "equal"
  
  # time model fit
  start <-Sys.time()
  
  # Determine total sample size
  N <- ceiling((EPV * P) / event_frac)
  N_star <- ceiling(5000/event_frac)
  
  # Simulate dataset
  df_train <- simulate_logit(N, P, rho, bp)
  df_test <- simulate_logit(N_star, P, rho, bp)
  
  # fit model
  rf <- fit_rf_model(df_train)
  ridge <- fit_logistic_ridge(df_train)
  mle <- fit_logistic_mle(df_train)
  
  # evaluate model
  results_rf <- evaluate_rf_model(rf, df_test)
  results_ridge <- evaluate_ridge_model(ridge, df_test)
  results_mle <- evaluate_mle_model(mle, df_test)
  
  end <-  Sys.time()
  end - start
  # about 2 seconds per model * 10 simulations * 72 models = 1,4000 seconds or 24 minutes
```


# run for all datasets
```{r}
set.seed(400)

EPV_vals <- c(5, 10, 50)
event_frac <- 0.5

P_vals <- c(4, 8, 12)
rho_vals <- c(0, 0.5)
beta_patterns <- c("equal", "strong", "noise", "halfnoise")

B <- 10  # number of Monte Carlo repetitions

save_results <- data.frame()

for (EPV in EPV_vals) {
  for (P in P_vals) {
    for (rho in rho_vals) {
      for (bp in beta_patterns) {
        for (b in 1:B) {
          
          # Determine total sample size
          N <- ceiling((EPV * P) / event_frac)
          N_star <- ceiling(5000/event_frac)
          
          # Simulate dataset
          df_train <- simulate_logit(N, P, rho, bp)
          df_test <- simulate_logit(N_star, P, rho, bp)
          
          # fit random forest
          fit <- fit_rf_model(df_train)
          
          # evaluate random forest
          eval_rf <- evaluate_rf_model(fit, df_test)
          
          ### Store combined ###
          combined <- eval_rf %>%
            mutate(
              EPV = EPV,
              P = P,
              rho = rho,
              beta_pattern = bp,
              sim = b
            )
          save_results <- rbind(save_results, combined)
        }
      }
    }
  }
}
```

```{r}
save_results$model <- "Random Forest"

write.csv(save_results, "simulations_rmse_mae/random_forest_simulation_extra_values.csv", row.names = F)
```

# ridge
```{r}
set.seed(400)

EPV_vals <- c(5, 10, 50)
event_frac <- 0.5

P_vals <- c(4, 8, 12)
rho_vals <- c(0, 0.5)
beta_patterns <- c("equal", "strong", "noise", "halfnoise")

B <- 10  # number of Monte Carlo repetitions

save_results <- data.frame()

for (EPV in EPV_vals) {
  for (P in P_vals) {
    for (rho in rho_vals) {
      for (bp in beta_patterns) {
        for (b in 1:B) {
          
          # Determine total sample size
          N <- ceiling((EPV * P) / event_frac)
          N_star <- ceiling(5000/event_frac)
          
          # Simulate dataset
          df_train <- simulate_logit(N, P, rho, bp)
          df_test <- simulate_logit(N_star, P, rho, bp)
          
          # fit ridge
          fit <- fit_logistic_ridge(dat = df_train)
          
          # evaluate random forest
          eval_rf <- evaluate_ridge_model(fit, df_test)
          
          ### Store combined ###
          combined <- eval_rf %>%
            mutate(
              EPV = EPV,
              P = P,
              rho = rho,
              beta_pattern = bp,
              sim = b
            )
          save_results <- rbind(save_results, combined)
        }
      }
    }
  }
}
```

```{r}
save_results$model <- "Ridge"

write.csv(save_results, "simulations_rmse_mae/ridge_simulation_extra_values.csv", row.names = F)
```

```{r}
set.seed(400)

EPV_vals <- c(5, 10, 50)
event_frac <- 0.5

P_vals <- c(4, 8, 12)
rho_vals <- c(0, 0.5)
beta_patterns <- c("equal", "strong", "noise", "halfnoise")

B <- 10  # number of Monte Carlo repetitions

save_results <- data.frame()

for (EPV in EPV_vals) {
  for (P in P_vals) {
    for (rho in rho_vals) {
      for (bp in beta_patterns) {
        for (b in 1:B) {
          
          # Determine total sample size
          N <- ceiling((EPV * P) / event_frac)
          N_star <- ceiling(5000/event_frac)
          
          # Simulate dataset
          df_train <- simulate_logit(N, P, rho, bp)
          df_test <- simulate_logit(N_star, P, rho, bp)
          
          # fit random forest
          fit <- fit_logistic_mle(df_train)
          
          # evaluate random forest
          eval_rf <- evaluate_mle_model(fit, df_test)
          
          ### Store combined ###
          combined <- eval_rf %>%
            mutate(
              EPV = EPV,
              P = P,
              rho = rho,
              beta_pattern = bp,
              sim = b
            )
          save_results <- rbind(save_results, combined)
        }
      }
    }
  }
}
```

```{r}
save_results$model <- "MLE"

write.csv(save_results, "simulations_rmse_mae/mle_simulation_extra_values.csv", row.names = F)
```


